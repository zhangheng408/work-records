##### 2018/02/24 星期六
* tb_gen_code
	* 测试发现都是在tb_find/318处调用
	* 目前只有这个地方调用tb_gen_code
* riscv_cpu_realize/157
	* qemu_init_vcpu
		* qemu_tcg_init_vcpu/1388
			* qemu_tcg_cpu_thread_fn/1177 这个函数为啥出现两次
				* tcg_exec_all/1583
					* tcg_cpu_exec/1549
						* cpu_exec/613 这个函数出现了很多次，main execution loop
* cpu_exec
	* cpu_handle_halt
	* 设定tcg_current_cpu
	* atomic_mb_read(&exit_request)
	* cc->cpu_exec_enter(cpu) 这里应该是个空函数
	* init_delay_params 主/客之间的时钟延时等，暂时不关心
	* for(;;) 第一层大循环
		* sigsetjmp 这是一个分支，应该只走上半部分
		* cpu_handle_exception 先处理异常
		* reset TLB before first TB lookup
		* for(;;) 第二层循环
			* cpu_handle_interrupt
			* tb_find
				* cpu_get_tb_cpu_state
				* tb = atomic_rcu_read(&cpu->tb_jmp_cache[tb_jmp_cache_hash_func(pc)])
					* 查cache
				* tb_htable_lookup
					* 查hash表
				* 加锁
				* tb = tb_htable_lookup(cpu, pc, cs_base, flags);
					* 锁内再查一遍
				* tb = tb_gen_code(cpu, pc, cs_base, flags, 0);
				* 解锁
				* atomic_set(&cpu->tb_jmp_cache[tb_jmp_cache_hash_func(pc)], tb)
					* 更新cache
			* cpu_loop_exec_tb 执行代码
				* trace_exec_tb(tb,
				* cpu_tb_exec
					* tcg_qemu_tb_exec 就是tcg_ctx.code_gen_prologue
					* trace_exec_tb_exit
					* cc->synchronize_from_tb(cpu, last_tb);
						* 属于退出后的处理代码
				* 根据*tb_exit做一定处理
			* align_clocks
	* cc->cpu_exec_exit(cpu)
	* 设置current_cpu为空
* tcg_ctx.code_gen_prologue
	* tcg_prologue_init中被初始化s->code_gen_buffer
		* code_gen_alloc中alloc_code_gen_buffer();
			* 在tcg_exec_init中被调用

##### 2018/02/22 星期日
* kvm中有函数gfn_to_pfn_atomic
	* __gfn_to_pfn_memslot
		* __gfn_to_hva_many
			* __gfn_to_hva_memslot 获取了HVA
				* slot->userspace_addr + (gfn - slot->base_gfn) * PAGE_SIZE;
		* 判断了各种错误
		* hva_to_pfn
			* hva_to_pfn_fast 这里应该是正常的页错误机制
				* __get_user_pages_fast
			* hva_to_pfn_slow 这里应该由IO
* MIPS
	* kvm_mips_handle_exit
		* kvm_trap_vz_handle_tlb_ld_miss 是handle_tlb_ld_miss指针
			* kvm_mips_handle_vz_root_tlb_fault
				* kvm_mips_map_page

##### 2018/02/21 星期三
* 阅读内核中pagemap相关代码
	* 有点乱
	* 看不出内核中应该怎么进行虚实地址转换
* 从qemu-kvm的存储添加着手
	* kvm_region_add
		* kvm_set_phys_mem(kml, section, true)
			* size进行页对齐
			* 获取host虚拟地址ram
				* block->host + offset + section->offset_within_region + delta
			* 死循环检查overlap
			* 设定KVMSlot
				* mem->memory_size = size;
					* section->size存储大小
				* mem->start_addr = start_addr;
					* section->offset_within_address_space
					* 应该就是物理地址
				* mem->ram = ram;
					* host虚拟地址
				* mem->flags = kvm_mem_flags(mr)
					* dirty log和read only
			* kvm_set_user_memory_region
				* 设定kvm_userspace_memory_region
					* mem.slot = slot->slot | (kml->as_id << 16);
					* mem.guest_phys_addr = slot->start_addr;物理地址
					* mem.userspace_addr = (unsigned long)slot->ram;host虚拟地址
					* mem.flags = slot->flags;
					* mem.memory_size = slot->memory_size;
				* kvm_vm_ioctl
					* 
* qemu_ram_alloc
	* qemu_ram_alloc_internal
		* ram_block_add
			* phys_mem_alloc指针qemu_anon_ram_alloc
				* qemu_ram_mmap
					* mmap申请存储
						* 返回值就是block->host，应该是host虚拟地址
* kvm_vm_ioctl_set_memory_region
	* 检查KVM_USER_MEM_SLOTS
	* kvm_set_memory_region
		* 加锁kvm->slots_lock
		* __kvm_set_memory_region
			* check_memory_region_flags只有dirty log和read only
			* 检查用户空间地址是否可以访问
			* 检查overlaps
			* kvm_arch_create_memslot 这里应该是重点
				* 对KVM_NR_PAGE_SIZES的遍历
					* 申请了slot->arch.rmap[i]
					* 设定slot->arch.lpage_info[i - 1] = linfo;
						* 主要和对应层级页面大小相关
			* kvm_create_dirty_bitmap 还没完全理解dirty
			* 中间有KVM_MR_DELETE/KVM_MR_MOVE的分支
			* kvm_arch_prepare_memory_region x86是空的
			* update_memslots 更新kvm_memslots结构体相关变量
			* install_new_memslots
				* kvm_arch_memslots_updated(kvm, slots);
					* kvm_mmu_invalidate_mmio_sptes 避免slots->generation溢出
			* kvm_arch_commit_memory_region
				* kvm_mmu_calculate_mmu_pages 计算当前的申请的页面？
				* kvm_mmu_change_mmu_pages
					* prepare_zap_oldest_mmu_page
						* kvm_mmu_prepare_zap_page
					* kvm_mmu_commit_zap_page
				* kvm_mmu_zap_collapsible_sptes 和dirty log相关
				* kvm_mmu_slot_apply_flags
					* 代码中提到了fast_page_fault
					* 果然还是在页错误中建立页表
			* kvm_free_memslot(kvm, &old, &new);
			* kvfree(old_memslots);
		* 解锁kvm->slots_lock
* tdp就是Two-Dimensional-Paging
	* 在vmx中就是EPT了吧
	* vmx中的代码也确实如此
* init_kvm_mmu
	* init_kvm_tdp_mmu设定context->page_fault = tdp_page_fault
	* vmx设定了开启tdp
* kvm_arch_async_page_ready 这个估计不是重点
* kvm_arch_vcpu_ioctl_run
	* 检查vcpu是否要退出
	* vcpu_run
		* 此中有死循环，不不断进入客户端
		* vcpu_enter_guest
			* kvm_check_request，检查了很多请求
			* 加载了很多
			* kvm_x86_ops->run(vcpu);
			* 做了很多处理
			* vmx_handle_exit vmx的handle_exit函数指针
				* 设定了一些vcpu->run等
				* handle_exception 是kvm_vmx_exit_handlers[0]函数指针
					* 也是很多检查
						* kvm_handle_page_fault
							* 根据vcpu->arch.apf.host_apf_reason执行不同函数
							* kvm_mmu_page_fault 一般应该是这个函数
								* handle_mmio_page_fault 判断是否是mmio
								* tdp_page_fault 是kvm_mmu* context->page_fault函数指针
									* fast_page_fault
* tdp_page_fault
	* mmu_topup_memory_caches 为啥要先把cache加满？
	* check_hugepage_cache_consistency
	* mapping_level
	* fast_page_fault 这里可能不是建立页表用的
	* try_async_pf 这里可能是重点
		* __gfn_to_pfn_memslot 获取pfn
	* handle_abnormal_pfn
	* mmu_notifier_retry
	* make_mmu_pages_available
	* __direct_map

##### 2018/02/17 星期六
* 整理之前的修改

##### 2018/02/12 星期一
* 地址转换失败的问题
	* addr 0x802000a0, access_type 0x2, mmu_idx 0x1, retaddr 0x0, ret 1, pc 0x802000a0, bpc 0x0
	* 这是刚进入内核，刚刚切换为虚拟地址时，执行auipc出错
	* addr 0x0, access_type 0x0, mmu_idx 0x1, retaddr 0x7f4584a38707, ret 1, pc 0xffffffe0005878ca, bpc 0x0
	* 错误在cmpxchg_futex_value_locked，但是此时禁用了页错误
	* 之后出现了很多，低地址pc的错误，感觉这些pc都不会出现啊
		* 如pc 0xbdb02
	* addr 0x200048f000, access_type 0x1, mmu_idx 0x1, retaddr 0x7f59464418bc, ret 1, pc 0xffffffe0006e4c48, bpc 0x0
		* 这里是__copy_user的错误
		* 回头需要好好看
	* tlb_fill/404: addr 0x2000496000, access_type 0x1, mmu_idx 0x0, retaddr 0x7f59464f18ff, ret 1, pc 0x21b10, bpc 0x0
		* 这个pc也很怪，难道是输出的问题？但是前面都对啊
	* addr 0xffffffe00055a3ce, access_type 0x0, mmu_idx 0x0, retaddr 0x7f5946503ed1, ret 1, pc 0x80002512, bpc 0xffffffe00055a3ce
		* 地址有错误
			* 难道翻译对了？
			* 好像可以对，host的对应地址有内容啊
			* 此时pc对应的是illegal_insn_trap函数
				* 还是有些错误
* 还行先把guest的页表建立好吧

##### 2018/02/11 星期日
* 目前问题
	* kernel entry是typo造成不对
	
##### 2018/02/10 星期六
* 修改kvm
	* 增加bpc的操作
* 修改qemu
	* 使两层页表产生异常
	* 结果还没有异常
* tlb_fill/404: addr 0xffffffe080000000, access_type 0x2, mmu_idx 0x3, retaddr 0x0, ret 2, pc 0xffffffe080000000, bpc 0xffffffe00055a3aa
	* mmu idx为啥是3
	* access_type
		* 0 数据加载
		* 1 数据存储
		* 2 指令加载
	* pc为啥是高地址，不是低地址
		* 而且没有加1K偏移啊
* 未完成
	* pc对不对, kernel entry怎么样
		* 看新的kernel log
	* 之后为啥没退出
	* get_page_addr_code该怎么处理异常？
		* 必须是个对的地址？
		* 还是进入前，先检查？

##### 2018/02/07 星期三
* tlb_table
	* 定义在include/exec/cpu-defs.h
	* CPUTLBEntry tlb_table[NB_MMU_MODES][CPU_TLB_SIZE];
		* NB_MMU_MODES为4
		* CPU_TLB_SIZE应该是1<<8(256)
	* CPUTLBEntry tlb_v_table[NB_MMU_MODES][CPU_VTLB_SIZE];
		* CPU_VTLB_SIZE是8
		* use a fully associative victim tlb of 8 entries
	* CPUIOTLBEntry iotlb[NB_MMU_MODES][CPU_TLB_SIZE];
	* CPUIOTLBEntry iotlb_v[NB_MMU_MODES][CPU_VTLB_SIZE];
* CPUTLBEntry
	* target_ulong addr_read;
	* target_ulong addr_write;
	* target_ulong addr_code;
		* 上面三个好像都是虚拟地址
	* uintptr_t addend; 
		* 好像虚拟地址加上这个加数，就是物理地址
* CPUIOTLBEntry
	* hwaddr addr;
	* MemTxAttrs attrs;
* get_page_addr_code
	* iotlb_to_region有点复杂
	* 可以先修改do_unassigned_access，跳过这个错误
	* 但是tlb_table涉及虚实地址转换，一定要搞清楚
	* 具体应该在cpu_ldub_code
		* 应该和cpu_ldl_code定义类似
		* cpu_ldub_code_ra
		* 首先是tlb_table[mmu_idx][page_index].ADDR_READ的检查
		* 之后应该执行helper_ret_ldb_cmmu
			* 在tcg/tcg.h中找到了声明，但是没有定义
			* helper_le_ld_name/softmmu_template.h
* helper_be_ld_name
	* 先检查对齐
	* 重新加载tlb项
		* 先检查VICTIM_TLB_HIT
		* 再执行tlb_fill
			* 这是架构定义的函数
			* 会执行riscv_cpu_handle_mmu_fault
* 修改qemu
	* unaccessed，在虚拟态直接返回
	* tlb_flush
		* hret执行的设置特权级的指令，会flush_tlb
		* 只在vm exit的时候，增加flush_tlb
	* 但是还是会出错
		* Bad ram pointer 0xffffffffffffffff
		* 还是get_page_addr_code的错误
		* 怀疑是kvm没有初始化pc造成的
* kvm之中设置pc之后
	* helper_ret_ldb_cmmu/168: addr 0x0, tlb_addr 0xffffffffffffffff
	* 需要查一下pc传递问题，还有tlb_table到底在哪里设置
	
##### 2018/02/04 星期日
* 学习了金融学的现值关系和分布式系统中的拜占庭错误
* 虚拟化代码实现很龟速啊
* 正常很早就应该实现了，现在应该开始文档了
* 而且阿里那么还没看好，问清楚
* i368没有实现cc->do_unassigned_access指针
	* 这其实和riscv是一样的效果，都是qemu直接退出
* cpu_ldl_code的定义
	* 目前还没找到它的定义
	* 可能是个宏，或者是个系统函数
	* 尝试反编译qemu，查看该函数
		* 反编译的qemu没有函数，经过太多的优化了
		* 尝试静态编译，失败
			* 有些库不能静态ld链接
	* 但是宏定义没找到呢
		* 似乎是个宏，网页中看到了定义
		* #define cpu_ldl_code(env1, p) ldl_raw(p)
		* 在cpu-all.h中
			* 现在这个文件在include/exec/cpu-all.h
		* 这个函数ldl表示load long
		* 这个函数可能是和大小端相关
	* 找到了这个定义
		* 在include/exec/cpu_ldst.h中
		* 具体定义在include/exec/cpu_ldst_template.h中
		* 其中使用了glue等进行函数名称的字符串拼接
		* 可能执行的函数
			* helper_ret_ldl_code
				* 这个函数估计没定义
			* ldl_p
				* ldl_he_p
					* 拷贝内容
				* le_bswap
					* 进行变换
			* 具体根据env->tlb_table选择
	* 这个函数搞清楚也没用，还得先把get_page_addr_code搞好
* RISCV是小端序，little endian
* get_page_addr_code
	* cpu_mmu_index
		* 这个是架构定义的
		* 原本是返回特权态，现在可以增加虚拟化标志位
	* 是更新env->tlb_table吗？
		* 需要清晰tlb_table的定义，初始化和作用等
		* 看样子就是一个tlb的作用，需要再看看

##### 2018/02/03 星期六
* 阅读了qemu中的helper_vmrun函数
	* 并没有太多指导意义
* 需要了解的东西
	* SVM使用的EPT，在qemu如何使用
	* 两级地址转换和取指操作如何协同
* riscv/translate.c
	* riscv_tcg_init
		* 并没有注册任何函数指针
		* 估计函数是直接定义的
	* riscv_cpu_dump_state
		* cc->dump_state
			* cpu_abort
			* hw_error
	* gen_intermediate_code
		* tb_gen_code这个函数应该被重点关注
	* 其他函数都被static修饰，着重关注以上两者
* tb_gen_code
	* **phys_pc = get_page_addr_code(env, pc)**
		* tb应该是用物理地址标识的
		* 虽然翻译的时候用不到
		* 其中涉及到了tlb_table相关
			* 应该不适合直接在cc->do_unassigned_access函数中实现地址转换
	* 申请tb，并初始化
	* tcg_func_start(&tcg_ctx);
		* tcg上下文相关，暂时不关心
	* gen_intermediate_code(env, tb);
		* **ctx.opcode = cpu_ldl_code(env, ctx.pc);**
			* 需要看一下这个函数在哪定义，可能是宏定义
		* decode_opc(env, &ctx);
		* ctx.pc = ctx.next_pc;
			* 这就是主循环体
	* phys_page2 = get_page_addr_code(env, virt_page2);
* 关于虚拟化存储管理
	* 不一定需要两级页表，让存储隔离且共存
	* 完全可以告诉OS，只有哪些是可以访问
	* 硬件保证，只有这些可以访问
* qemu中的svm嵌套页表
	* SVM的两级页表中
		* GPA->HPA的页表，VMM的页表不相同，不是同一个
	* 没有找到相关的代码
	* 看到了nested_cr3定义
	* 但是没有看到使用nested_cr3
	* 很可能qemu中还是没有实现虚拟化，这个定义只是为了使用kvm
	* 那我之前使用的是什么呢？
##### 2018/02/02 星期五
* 虚拟机PC问题
	* 目前看来pc还是不设置为虚拟机地址了吧
		* 这样需要提供一个pc初始化ioctl接口
	* 如果设置要将pc设置为GVA，需要修改do_unassigned_access等函数
	* 暂时还不确定这样修改是否正确
* 目前需要的调研
	* amd svm在qemu中是怎么做的？
		* 这个需要详细看看
	* 内核中地址模式切换时，pc如何改变？是虚拟地址吗？
		* 似乎是虚拟地址



